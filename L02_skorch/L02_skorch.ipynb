{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "\n",
    "* torchのtrainループ書くのだるいな〜ってときに。\n",
    "\n",
    "* datasetの定義 → dataloaderの定義 → trainループを書く　\n",
    "\n",
    "                   ⇓    skorchを使うと\n",
    "                   \n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "   　　　　clf.fit(x_train, y_train)\n",
    "                \n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "* 参考　（というかほぼこれ）\n",
    "\n",
    "https://www.pytry3g.com/entry/skorch-tutorial\n",
    "\n",
    "* 実行確認環境\n",
    "\n",
    "    torch==1.3.1\n",
    "    \n",
    "    scikit-learn==0.21.3\n",
    "    \n",
    "    skorch==0.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量準備およびネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X = wine.data.astype(np.float32)\n",
    "y = wine.target.astype(np.int64)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=wine.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 30)\n",
    "        self.fc2 = nn.Linear(30, 30)\n",
    "        self.fc3 = nn.Linear(30, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skorchを使ってみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NeuralNetClassifier(\n",
    "    Net,\n",
    "    optimizer = torch.optim.SGD,\n",
    "    criterion = nn.CrossEntropyLoss,\n",
    "    max_epochs = 100,\n",
    "    lr = 0.001,\n",
    "    iterator_train__batch_size=32, # default=128\n",
    "    iterator_train__shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m26.7046\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m4.3661\u001b[0m  0.0763\n",
      "      2        \u001b[36m4.9759\u001b[0m       0.3333        \u001b[35m3.7588\u001b[0m  0.0038\n",
      "      3        \u001b[36m4.6667\u001b[0m       \u001b[32m0.4000\u001b[0m        \u001b[35m1.4078\u001b[0m  0.0037\n",
      "      4        \u001b[36m1.4011\u001b[0m       \u001b[32m0.7333\u001b[0m        \u001b[35m0.7109\u001b[0m  0.0027\n",
      "      5        1.7998       0.2667        1.8648  0.0027\n",
      "      6        \u001b[36m1.2832\u001b[0m       0.5333        0.8326  0.0028\n",
      "      7        \u001b[36m0.8703\u001b[0m       0.5667        0.7577  0.0027\n",
      "      8        0.9239       0.6000        0.8386  0.0026\n",
      "      9        0.9376       0.6333        0.8805  0.0026\n",
      "     10        0.9093       0.6667        0.7351  0.0026\n",
      "     11        \u001b[36m0.7793\u001b[0m       0.7333        \u001b[35m0.6264\u001b[0m  0.0027\n",
      "     12        \u001b[36m0.7676\u001b[0m       0.7333        \u001b[35m0.6042\u001b[0m  0.0026\n",
      "     13        \u001b[36m0.7524\u001b[0m       0.7333        0.6466  0.0031\n",
      "     14        0.7710       0.5667        0.8324  0.0030\n",
      "     15        1.0122       0.7333        0.6705  0.0032\n",
      "     16        0.8152       \u001b[32m0.7667\u001b[0m        \u001b[35m0.5904\u001b[0m  0.0031\n",
      "     17        0.9101       0.7333        0.5993  0.0030\n",
      "     18        0.9686       0.7333        0.7035  0.0031\n",
      "     19        0.7824       0.7333        0.5972  0.0035\n",
      "     20        0.7536       0.7333        0.6065  0.0032\n",
      "     21        0.7565       0.7333        0.6413  0.0032\n",
      "     22        0.7934       0.6333        0.6966  0.0036\n",
      "     23        0.7928       0.7000        0.6234  0.0030\n",
      "     24        0.7931       0.7333        0.6455  0.0030\n",
      "     25        \u001b[36m0.7512\u001b[0m       \u001b[32m0.8333\u001b[0m        \u001b[35m0.5546\u001b[0m  0.0032\n",
      "     26        0.7909       0.7333        0.5746  0.0029\n",
      "     27        0.7517       0.5667        0.6698  0.0029\n",
      "     28        0.8050       0.7000        0.6031  0.0030\n",
      "     29        0.8329       0.7333        \u001b[35m0.5433\u001b[0m  0.0026\n",
      "     30        0.8815       0.6667        0.6531  0.0035\n",
      "     31        \u001b[36m0.7228\u001b[0m       0.7333        0.5613  0.0028\n",
      "     32        0.7280       0.7333        \u001b[35m0.5366\u001b[0m  0.0025\n",
      "     33        \u001b[36m0.6959\u001b[0m       0.7000        0.6539  0.0031\n",
      "     34        0.7859       0.8000        \u001b[35m0.5307\u001b[0m  0.0030\n",
      "     35        \u001b[36m0.6928\u001b[0m       0.8333        0.5431  0.0030\n",
      "     36        \u001b[36m0.6826\u001b[0m       0.7000        0.5924  0.0030\n",
      "     37        0.7013       0.6333        0.5681  0.0030\n",
      "     38        0.7265       0.7667        0.6232  0.0028\n",
      "     39        0.8150       0.8000        0.5401  0.0026\n",
      "     40        0.7010       0.6667        \u001b[35m0.5282\u001b[0m  0.0027\n",
      "     41        0.7106       0.8000        \u001b[35m0.5118\u001b[0m  0.0028\n",
      "     42        0.7136       0.8000        \u001b[35m0.5101\u001b[0m  0.0026\n",
      "     43        0.7028       0.8000        0.5125  0.0026\n",
      "     44        0.6856       0.7333        0.5575  0.0026\n",
      "     45        0.7127       0.8333        0.5190  0.0026\n",
      "     46        \u001b[36m0.6792\u001b[0m       0.7333        0.5260  0.0030\n",
      "     47        \u001b[36m0.6787\u001b[0m       0.7333        0.5145  0.0027\n",
      "     48        0.6875       0.7000        0.6354  0.0030\n",
      "     49        0.7500       0.6000        0.6818  0.0029\n",
      "     50        0.7444       \u001b[32m0.8667\u001b[0m        \u001b[35m0.5050\u001b[0m  0.0029\n",
      "     51        0.6914       0.7667        0.5088  0.0031\n",
      "     52        0.6971       0.8000        0.5181  0.0029\n",
      "     53        0.6930       0.7333        0.5318  0.0034\n",
      "     54        0.7903       0.7667        0.5325  0.0030\n",
      "     55        0.6810       0.8000        0.5589  0.0032\n",
      "     56        0.7286       0.7333        0.5643  0.0027\n",
      "     57        0.7788       0.7333        0.5114  0.0030\n",
      "     58        0.7128       0.7000        0.6401  0.0027\n",
      "     59        0.7259       0.8000        0.5391  0.0026\n",
      "     60        0.7230       0.7333        0.5221  0.0028\n",
      "     61        0.6978       0.7000        0.5776  0.0027\n",
      "     62        0.7147       0.7667        0.5387  0.0027\n",
      "     63        0.7810       0.7333        0.5387  0.0026\n",
      "     64        \u001b[36m0.6644\u001b[0m       0.7667        \u001b[35m0.4960\u001b[0m  0.0027\n",
      "     65        0.7339       0.7000        0.6223  0.0027\n",
      "     66        0.7129       0.6667        0.6161  0.0026\n",
      "     67        0.7933       0.7333        0.5532  0.0030\n",
      "     68        0.6717       0.8333        \u001b[35m0.4898\u001b[0m  0.0027\n",
      "     69        0.8325       0.7667        0.5214  0.0027\n",
      "     70        0.7064       0.7667        \u001b[35m0.4882\u001b[0m  0.0032\n",
      "     71        0.7106       0.6333        0.6790  0.0030\n",
      "     72        0.7685       0.8333        0.5023  0.0030\n",
      "     73        0.7022       0.6333        0.6713  0.0035\n",
      "     74        0.7576       0.7667        0.4955  0.0028\n",
      "     75        \u001b[36m0.6633\u001b[0m       0.8333        \u001b[35m0.4788\u001b[0m  0.0032\n",
      "     76        0.6656       0.7333        0.5384  0.0028\n",
      "     77        0.6856       0.7333        0.5101  0.0034\n",
      "     78        0.6787       0.7333        0.5108  0.0030\n",
      "     79        0.6778       0.8000        0.4832  0.0031\n",
      "     80        \u001b[36m0.6568\u001b[0m       0.7333        0.4840  0.0029\n",
      "     81        0.6942       0.7333        0.4957  0.0030\n",
      "     82        0.6729       0.7333        0.4946  0.0026\n",
      "     83        0.6764       0.7333        0.4821  0.0028\n",
      "     84        0.6802       0.5667        0.7836  0.0027\n",
      "     85        0.7911       0.8000        0.4870  0.0032\n",
      "     86        0.6597       0.8667        0.5592  0.0041\n",
      "     87        0.6844       0.7333        0.5498  0.0030\n",
      "     88        0.6878       0.7667        0.6028  0.0031\n",
      "     89        0.6924       0.7333        \u001b[35m0.4775\u001b[0m  0.0036\n",
      "     90        0.6841       0.8000        0.4853  0.0029\n",
      "     91        0.6766       0.7667        0.5013  0.0030\n",
      "     92        0.6778       0.6667        0.5604  0.0028\n",
      "     93        0.8265       0.7667        0.5333  0.0031\n",
      "     94        0.6868       0.5667        0.7366  0.0031\n",
      "     95        0.7534       0.7667        0.4847  0.0026\n",
      "     96        0.6580       0.8000        0.4919  0.0031\n",
      "     97        \u001b[36m0.6553\u001b[0m       0.7333        0.4967  0.0030\n",
      "     98        0.7149       0.7667        \u001b[35m0.4724\u001b[0m  0.0030\n",
      "     99        0.6672       0.8667        0.4809  0.0031\n",
      "    100        0.6595       0.7667        0.4735  0.0051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Net(\n",
       "    (fc1): Linear(in_features=13, out_features=30, bias=True)\n",
       "    (fc2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (fc3): Linear(in_features=30, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.67      0.86      0.75        14\n",
      "           2       0.50      0.40      0.44        10\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.69      0.67      0.67        36\n",
      "weighted avg       0.70      0.69      0.69        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yosuke-kurosu/.local/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/yosuke-kurosu/.local/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/yosuke-kurosu/.local/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "with open('samplenn.pkl', mode='wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"samplenn.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPUの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NeuralNetClassifier(\n",
    "    Net,\n",
    "    optimizer = torch.optim.SGD,\n",
    "    criterion = nn.CrossEntropyLoss,\n",
    "    max_epochs = 100,\n",
    "    lr = 0.001,\n",
    "    iterator_train__batch_size=32, # default=128\n",
    "    iterator_train__shuffle=True,\n",
    "    device = \"cuda\" # オプションにCUDAを追加する\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m9.7851\u001b[0m       \u001b[32m0.4000\u001b[0m        \u001b[35m3.8554\u001b[0m  0.1083\n",
      "      2        \u001b[36m4.6137\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.3664\u001b[0m  0.0137\n",
      "      3        \u001b[36m2.3092\u001b[0m       0.4000        2.5766  0.0041\n",
      "      4        2.3896       0.4000        \u001b[35m1.5512\u001b[0m  0.0042\n",
      "      5        \u001b[36m1.9207\u001b[0m       0.4000        3.4217  0.0042\n",
      "      6        2.0388       \u001b[32m0.6667\u001b[0m        \u001b[35m0.7240\u001b[0m  0.0042\n",
      "      7        \u001b[36m0.8315\u001b[0m       0.6333        0.8974  0.0047\n",
      "      8        0.9262       0.4000        1.8385  0.0051\n",
      "      9        1.5752       0.4000        1.4823  0.0040\n",
      "     10        1.0791       \u001b[32m0.7333\u001b[0m        \u001b[35m0.6428\u001b[0m  0.0037\n",
      "     11        \u001b[36m0.7826\u001b[0m       0.7000        0.6475  0.0047\n",
      "     12        0.8909       0.7333        0.7581  0.0040\n",
      "     13        1.1138       0.5333        0.8386  0.0039\n",
      "     14        0.9933       0.6000        0.6889  0.0045\n",
      "     15        0.9210       0.7333        \u001b[35m0.6372\u001b[0m  0.0043\n",
      "     16        \u001b[36m0.7633\u001b[0m       0.4667        1.0770  0.0044\n",
      "     17        0.9554       0.7333        0.6485  0.0050\n",
      "     18        \u001b[36m0.7381\u001b[0m       0.7333        \u001b[35m0.5891\u001b[0m  0.0037\n",
      "     19        0.8773       0.7333        0.6208  0.0044\n",
      "     20        0.7413       0.7333        0.6490  0.0049\n",
      "     21        0.7503       0.5000        0.8179  0.0047\n",
      "     22        0.7895       0.5667        0.7982  0.0048\n",
      "     23        0.8610       0.7333        \u001b[35m0.5610\u001b[0m  0.0038\n",
      "     24        \u001b[36m0.7160\u001b[0m       \u001b[32m0.8000\u001b[0m        0.6118  0.0037\n",
      "     25        0.7561       0.7333        \u001b[35m0.5443\u001b[0m  0.0049\n",
      "     26        0.7217       0.7333        0.6399  0.0041\n",
      "     27        0.7685       0.6667        0.5808  0.0044\n",
      "     28        0.8119       0.7333        0.6275  0.0043\n",
      "     29        0.7745       0.7000        0.5674  0.0046\n",
      "     30        \u001b[36m0.7002\u001b[0m       0.7000        0.6486  0.0056\n",
      "     31        0.7668       0.7333        0.5784  0.0045\n",
      "     32        0.7718       0.7667        0.5534  0.0046\n",
      "     33        \u001b[36m0.6956\u001b[0m       0.7333        \u001b[35m0.5387\u001b[0m  0.0042\n",
      "     34        \u001b[36m0.6771\u001b[0m       0.7333        \u001b[35m0.5265\u001b[0m  0.0043\n",
      "     35        0.7127       \u001b[32m0.8333\u001b[0m        \u001b[35m0.5137\u001b[0m  0.0046\n",
      "     36        0.6913       0.7333        0.5832  0.0043\n",
      "     37        0.7071       0.8333        \u001b[35m0.5108\u001b[0m  0.0044\n",
      "     38        0.6998       0.7000        0.6166  0.0049\n",
      "     39        0.7824       0.7333        0.5936  0.0045\n",
      "     40        0.6909       0.6667        0.6612  0.0045\n",
      "     41        0.7667       0.7333        0.5451  0.0046\n",
      "     42        0.7211       0.8000        \u001b[35m0.4985\u001b[0m  0.0051\n",
      "     43        0.7057       0.7333        0.5244  0.0037\n",
      "     44        0.7466       0.7667        0.5110  0.0038\n",
      "     45        0.6835       0.7333        0.5308  0.0051\n",
      "     46        0.7031       0.7333        0.5930  0.0044\n",
      "     47        0.7205       0.7000        0.6408  0.0052\n",
      "     48        0.7676       0.7333        0.5038  0.0044\n",
      "     49        0.7468       0.7333        0.5864  0.0046\n",
      "     50        0.7581       0.7667        0.5375  0.0044\n",
      "     51        0.7530       0.7333        0.5372  0.0057\n",
      "     52        0.6812       0.8333        \u001b[35m0.4964\u001b[0m  0.0042\n",
      "     53        \u001b[36m0.6733\u001b[0m       0.6667        0.6187  0.0043\n",
      "     54        0.8434       0.7000        0.5808  0.0048\n",
      "     55        0.7123       0.7667        0.4978  0.0038\n",
      "     56        0.6840       0.7333        0.5186  0.0041\n",
      "     57        0.6964       0.5667        0.8503  0.0042\n",
      "     58        0.9012       0.5333        0.8736  0.0045\n",
      "     59        0.9230       0.7333        0.5292  0.0048\n",
      "     60        0.7167       0.7667        \u001b[35m0.4907\u001b[0m  0.0043\n",
      "     61        0.6807       0.7333        0.5494  0.0045\n",
      "     62        0.6840       0.7667        0.5002  0.0042\n",
      "     63        \u001b[36m0.6635\u001b[0m       0.6667        0.5853  0.0040\n",
      "     64        0.6861       0.7333        0.5171  0.0039\n",
      "     65        0.6936       0.7333        0.5129  0.0038\n",
      "     66        0.7298       0.6667        0.6129  0.0049\n",
      "     67        0.6847       0.8000        0.4931  0.0043\n",
      "     68        0.6838       0.7667        0.5040  0.0053\n",
      "     69        0.6756       0.7333        0.5049  0.0042\n",
      "     70        0.7096       0.7667        0.4987  0.0044\n",
      "     71        0.6684       0.7667        0.4932  0.0039\n",
      "     72        0.6694       0.7667        0.5137  0.0042\n",
      "     73        0.6908       0.7333        0.5033  0.0046\n",
      "     74        0.6874       0.7000        0.5469  0.0042\n",
      "     75        0.6873       0.7333        0.5577  0.0058\n",
      "     76        0.6723       0.8333        0.5403  0.0039\n",
      "     77        0.8359       0.8333        0.4908  0.0042\n",
      "     78        0.7374       0.8000        \u001b[35m0.4809\u001b[0m  0.0044\n",
      "     79        0.7022       0.7000        0.6162  0.0057\n",
      "     80        0.6870       0.6667        0.6293  0.0044\n",
      "     81        0.6871       0.8000        0.4838  0.0047\n",
      "     82        0.6818       0.7000        0.5546  0.0046\n",
      "     83        0.7027       0.7333        0.4944  0.0050\n",
      "     84        0.6854       0.6333        0.6759  0.0043\n",
      "     85        0.8800       0.7333        0.4963  0.0048\n",
      "     86        0.6710       0.8333        0.4935  0.0041\n",
      "     87        0.6742       0.7333        0.4891  0.0043\n",
      "     88        0.6977       0.7000        0.5147  0.0041\n",
      "     89        0.7144       0.7333        0.5717  0.0043\n",
      "     90        0.6989       0.7667        \u001b[35m0.4717\u001b[0m  0.0041\n",
      "     91        0.6639       0.7333        0.4960  0.0039\n",
      "     92        0.7486       0.7333        0.5319  0.0042\n",
      "     93        0.6726       0.6333        0.6476  0.0039\n",
      "     94        0.7660       0.7667        0.4927  0.0041\n",
      "     95        0.7402       0.7000        0.5293  0.0048\n",
      "     96        0.7276       0.7333        0.4790  0.0049\n",
      "     97        0.6655       0.7333        0.5108  0.0047\n",
      "     98        0.6798       0.7667        0.4807  0.0047\n",
      "     99        0.6816       0.7667        0.4972  0.0046\n",
      "    100        0.6757       0.7333        0.5275  0.0049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Net(\n",
       "    (fc1): Linear(in_features=13, out_features=30, bias=True)\n",
       "    (fc2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (fc3): Linear(in_features=30, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプラインの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.1489\u001b[0m       \u001b[32m0.2333\u001b[0m        \u001b[35m1.1608\u001b[0m  0.0042\n",
      "      2        \u001b[36m1.1483\u001b[0m       0.2333        \u001b[35m1.1602\u001b[0m  0.0046\n",
      "      3        \u001b[36m1.1476\u001b[0m       0.2333        \u001b[35m1.1595\u001b[0m  0.0047\n",
      "      4        \u001b[36m1.1469\u001b[0m       0.2333        \u001b[35m1.1588\u001b[0m  0.0044\n",
      "      5        \u001b[36m1.1463\u001b[0m       0.2333        \u001b[35m1.1582\u001b[0m  0.0044\n",
      "      6        \u001b[36m1.1457\u001b[0m       0.2333        \u001b[35m1.1575\u001b[0m  0.0046\n",
      "      7        \u001b[36m1.1450\u001b[0m       0.2333        \u001b[35m1.1569\u001b[0m  0.0048\n",
      "      8        \u001b[36m1.1444\u001b[0m       0.2333        \u001b[35m1.1562\u001b[0m  0.0046\n",
      "      9        \u001b[36m1.1437\u001b[0m       0.2333        \u001b[35m1.1556\u001b[0m  0.0049\n",
      "     10        \u001b[36m1.1431\u001b[0m       0.2333        \u001b[35m1.1549\u001b[0m  0.0049\n",
      "     11        \u001b[36m1.1424\u001b[0m       0.2333        \u001b[35m1.1542\u001b[0m  0.0053\n",
      "     12        \u001b[36m1.1417\u001b[0m       0.2333        \u001b[35m1.1536\u001b[0m  0.0040\n",
      "     13        \u001b[36m1.1411\u001b[0m       0.2333        \u001b[35m1.1530\u001b[0m  0.0044\n",
      "     14        \u001b[36m1.1405\u001b[0m       0.2333        \u001b[35m1.1524\u001b[0m  0.0045\n",
      "     15        \u001b[36m1.1399\u001b[0m       0.2333        \u001b[35m1.1517\u001b[0m  0.0039\n",
      "     16        \u001b[36m1.1393\u001b[0m       0.2333        \u001b[35m1.1511\u001b[0m  0.0045\n",
      "     17        \u001b[36m1.1386\u001b[0m       0.2333        \u001b[35m1.1505\u001b[0m  0.0039\n",
      "     18        \u001b[36m1.1380\u001b[0m       0.2333        \u001b[35m1.1498\u001b[0m  0.0040\n",
      "     19        \u001b[36m1.1374\u001b[0m       0.2333        \u001b[35m1.1492\u001b[0m  0.0051\n",
      "     20        \u001b[36m1.1368\u001b[0m       0.2333        \u001b[35m1.1485\u001b[0m  0.0046\n",
      "     21        \u001b[36m1.1361\u001b[0m       0.2333        \u001b[35m1.1479\u001b[0m  0.0051\n",
      "     22        \u001b[36m1.1355\u001b[0m       0.2333        \u001b[35m1.1473\u001b[0m  0.0046\n",
      "     23        \u001b[36m1.1349\u001b[0m       0.2333        \u001b[35m1.1467\u001b[0m  0.0048\n",
      "     24        \u001b[36m1.1343\u001b[0m       0.2333        \u001b[35m1.1461\u001b[0m  0.0050\n",
      "     25        \u001b[36m1.1337\u001b[0m       0.2333        \u001b[35m1.1454\u001b[0m  0.0042\n",
      "     26        \u001b[36m1.1331\u001b[0m       0.2333        \u001b[35m1.1448\u001b[0m  0.0047\n",
      "     27        \u001b[36m1.1325\u001b[0m       0.2333        \u001b[35m1.1442\u001b[0m  0.0044\n",
      "     28        \u001b[36m1.1319\u001b[0m       0.2333        \u001b[35m1.1436\u001b[0m  0.0053\n",
      "     29        \u001b[36m1.1313\u001b[0m       0.2333        \u001b[35m1.1430\u001b[0m  0.0052\n",
      "     30        \u001b[36m1.1307\u001b[0m       0.2333        \u001b[35m1.1424\u001b[0m  0.0038\n",
      "     31        \u001b[36m1.1301\u001b[0m       0.2333        \u001b[35m1.1418\u001b[0m  0.0055\n",
      "     32        \u001b[36m1.1295\u001b[0m       0.2333        \u001b[35m1.1412\u001b[0m  0.0044\n",
      "     33        \u001b[36m1.1289\u001b[0m       0.2333        \u001b[35m1.1406\u001b[0m  0.0051\n",
      "     34        \u001b[36m1.1283\u001b[0m       0.2333        \u001b[35m1.1400\u001b[0m  0.0039\n",
      "     35        \u001b[36m1.1278\u001b[0m       0.2333        \u001b[35m1.1394\u001b[0m  0.0039\n",
      "     36        \u001b[36m1.1272\u001b[0m       0.2333        \u001b[35m1.1388\u001b[0m  0.0039\n",
      "     37        \u001b[36m1.1266\u001b[0m       0.2333        \u001b[35m1.1382\u001b[0m  0.0047\n",
      "     38        \u001b[36m1.1260\u001b[0m       0.2333        \u001b[35m1.1376\u001b[0m  0.0047\n",
      "     39        \u001b[36m1.1254\u001b[0m       0.2333        \u001b[35m1.1370\u001b[0m  0.0044\n",
      "     40        \u001b[36m1.1248\u001b[0m       0.2333        \u001b[35m1.1364\u001b[0m  0.0044\n",
      "     41        \u001b[36m1.1242\u001b[0m       0.2333        \u001b[35m1.1358\u001b[0m  0.0049\n",
      "     42        \u001b[36m1.1237\u001b[0m       0.2333        \u001b[35m1.1353\u001b[0m  0.0046\n",
      "     43        \u001b[36m1.1231\u001b[0m       0.2333        \u001b[35m1.1347\u001b[0m  0.0051\n",
      "     44        \u001b[36m1.1225\u001b[0m       0.2333        \u001b[35m1.1341\u001b[0m  0.0039\n",
      "     45        \u001b[36m1.1220\u001b[0m       0.2333        \u001b[35m1.1335\u001b[0m  0.0054\n",
      "     46        \u001b[36m1.1214\u001b[0m       0.2333        \u001b[35m1.1330\u001b[0m  0.0045\n",
      "     47        \u001b[36m1.1209\u001b[0m       0.2333        \u001b[35m1.1324\u001b[0m  0.0045\n",
      "     48        \u001b[36m1.1203\u001b[0m       0.2333        \u001b[35m1.1318\u001b[0m  0.0045\n",
      "     49        \u001b[36m1.1197\u001b[0m       0.2333        \u001b[35m1.1312\u001b[0m  0.0047\n",
      "     50        \u001b[36m1.1192\u001b[0m       0.2333        \u001b[35m1.1307\u001b[0m  0.0047\n",
      "     51        \u001b[36m1.1186\u001b[0m       0.2333        \u001b[35m1.1301\u001b[0m  0.0045\n",
      "     52        \u001b[36m1.1181\u001b[0m       0.2333        \u001b[35m1.1296\u001b[0m  0.0043\n",
      "     53        \u001b[36m1.1175\u001b[0m       0.2333        \u001b[35m1.1290\u001b[0m  0.0042\n",
      "     54        \u001b[36m1.1170\u001b[0m       0.2333        \u001b[35m1.1284\u001b[0m  0.0041\n",
      "     55        \u001b[36m1.1164\u001b[0m       0.2333        \u001b[35m1.1278\u001b[0m  0.0049\n",
      "     56        \u001b[36m1.1158\u001b[0m       0.2333        \u001b[35m1.1273\u001b[0m  0.0046\n",
      "     57        \u001b[36m1.1153\u001b[0m       0.2333        \u001b[35m1.1268\u001b[0m  0.0045\n",
      "     58        \u001b[36m1.1148\u001b[0m       0.2333        \u001b[35m1.1262\u001b[0m  0.0043\n",
      "     59        \u001b[36m1.1142\u001b[0m       0.2333        \u001b[35m1.1257\u001b[0m  0.0045\n",
      "     60        \u001b[36m1.1137\u001b[0m       0.2333        \u001b[35m1.1251\u001b[0m  0.0043\n",
      "     61        \u001b[36m1.1132\u001b[0m       0.2333        \u001b[35m1.1246\u001b[0m  0.0049\n",
      "     62        \u001b[36m1.1127\u001b[0m       0.2333        \u001b[35m1.1240\u001b[0m  0.0042\n",
      "     63        \u001b[36m1.1121\u001b[0m       0.2333        \u001b[35m1.1235\u001b[0m  0.0061\n",
      "     64        \u001b[36m1.1116\u001b[0m       0.2333        \u001b[35m1.1229\u001b[0m  0.0043\n",
      "     65        \u001b[36m1.1110\u001b[0m       \u001b[32m0.2667\u001b[0m        \u001b[35m1.1224\u001b[0m  0.0043\n",
      "     66        \u001b[36m1.1105\u001b[0m       0.2667        \u001b[35m1.1219\u001b[0m  0.0039\n",
      "     67        \u001b[36m1.1099\u001b[0m       0.2667        \u001b[35m1.1213\u001b[0m  0.0053\n",
      "     68        \u001b[36m1.1094\u001b[0m       0.2667        \u001b[35m1.1208\u001b[0m  0.0052\n",
      "     69        \u001b[36m1.1089\u001b[0m       0.2667        \u001b[35m1.1203\u001b[0m  0.0045\n",
      "     70        \u001b[36m1.1084\u001b[0m       0.2667        \u001b[35m1.1197\u001b[0m  0.0045\n",
      "     71        \u001b[36m1.1079\u001b[0m       0.2667        \u001b[35m1.1192\u001b[0m  0.0045\n",
      "     72        \u001b[36m1.1073\u001b[0m       0.2667        \u001b[35m1.1187\u001b[0m  0.0043\n",
      "     73        \u001b[36m1.1068\u001b[0m       0.2667        \u001b[35m1.1181\u001b[0m  0.0043\n",
      "     74        \u001b[36m1.1063\u001b[0m       0.2667        \u001b[35m1.1176\u001b[0m  0.0044\n",
      "     75        \u001b[36m1.1058\u001b[0m       0.2667        \u001b[35m1.1171\u001b[0m  0.0042\n",
      "     76        \u001b[36m1.1053\u001b[0m       0.2667        \u001b[35m1.1166\u001b[0m  0.0042\n",
      "     77        \u001b[36m1.1048\u001b[0m       \u001b[32m0.3000\u001b[0m        \u001b[35m1.1161\u001b[0m  0.0042\n",
      "     78        \u001b[36m1.1042\u001b[0m       0.3000        \u001b[35m1.1156\u001b[0m  0.0044\n",
      "     79        \u001b[36m1.1037\u001b[0m       0.3000        \u001b[35m1.1150\u001b[0m  0.0044\n",
      "     80        \u001b[36m1.1033\u001b[0m       0.3000        \u001b[35m1.1145\u001b[0m  0.0044\n",
      "     81        \u001b[36m1.1027\u001b[0m       0.3000        \u001b[35m1.1140\u001b[0m  0.0042\n",
      "     82        \u001b[36m1.1022\u001b[0m       0.3000        \u001b[35m1.1135\u001b[0m  0.0041\n",
      "     83        \u001b[36m1.1017\u001b[0m       0.3000        \u001b[35m1.1130\u001b[0m  0.0043\n",
      "     84        \u001b[36m1.1012\u001b[0m       0.3000        \u001b[35m1.1125\u001b[0m  0.0045\n",
      "     85        \u001b[36m1.1007\u001b[0m       0.3000        \u001b[35m1.1119\u001b[0m  0.0043\n",
      "     86        \u001b[36m1.1001\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m1.1114\u001b[0m  0.0044\n",
      "     87        \u001b[36m1.0996\u001b[0m       0.3333        \u001b[35m1.1109\u001b[0m  0.0043\n",
      "     88        \u001b[36m1.0992\u001b[0m       0.3333        \u001b[35m1.1104\u001b[0m  0.0047\n",
      "     89        \u001b[36m1.0986\u001b[0m       0.3333        \u001b[35m1.1099\u001b[0m  0.0050\n",
      "     90        \u001b[36m1.0981\u001b[0m       0.3333        \u001b[35m1.1094\u001b[0m  0.0054\n",
      "     91        \u001b[36m1.0976\u001b[0m       0.3333        \u001b[35m1.1089\u001b[0m  0.0052\n",
      "     92        \u001b[36m1.0972\u001b[0m       0.3333        \u001b[35m1.1084\u001b[0m  0.0055\n",
      "     93        \u001b[36m1.0966\u001b[0m       0.3333        \u001b[35m1.1079\u001b[0m  0.0043\n",
      "     94        \u001b[36m1.0961\u001b[0m       0.3333        \u001b[35m1.1074\u001b[0m  0.0048\n",
      "     95        \u001b[36m1.0956\u001b[0m       0.3333        \u001b[35m1.1069\u001b[0m  0.0044\n",
      "     96        \u001b[36m1.0951\u001b[0m       0.3333        \u001b[35m1.1064\u001b[0m  0.0049\n",
      "     97        \u001b[36m1.0946\u001b[0m       0.3333        \u001b[35m1.1059\u001b[0m  0.0123\n",
      "     98        \u001b[36m1.0941\u001b[0m       0.3333        \u001b[35m1.1054\u001b[0m  0.0043\n",
      "     99        \u001b[36m1.0936\u001b[0m       0.3333        \u001b[35m1.1049\u001b[0m  0.0046\n",
      "    100        \u001b[36m1.0931\u001b[0m       \u001b[32m0.3667\u001b[0m        \u001b[35m1.1044\u001b[0m  0.0052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Net(\n",
       "    (fc1): Linear(in_features=13, out_features=30, bias=True)\n",
       "    (fc2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (fc3): Linear(in_features=30, out_features=3, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
